{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffe5917",
   "metadata": {},
   "source": [
    "# Identifying Pneumonina using Convolutional Neural Networks\n",
    "\n",
    "- Student Name: Kevin Spring\n",
    "- Student pace: Flex\n",
    "- Scheduled Project Review: December 12, 2022\n",
    "- Instructor name: Morgan Jones\n",
    "- Blog Post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27faa2a",
   "metadata": {},
   "source": [
    "# Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d93853",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e7f38",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573de929",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fe8388",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data.zip file and unpack it into test-train split using python_splitter\n",
    "import os\n",
    "from python_splitter import split_from_folder # https://github.com/bharatadk/python_splitter\n",
    "\n",
    "# absolute path of unzipped data directory\n",
    "PATH = os.path.join(os.path.abspath(os.getcwd()),'data\\\\')\n",
    "split_from_folder(PATH, train = 0.8, test=0.2)\n",
    "#pneumonia_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d06b58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9392/3956994212.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587b11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14039009617357312798\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8930076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.config' has no attribute 'list_physical_devices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8312\\4227348532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_dw_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accessing local variables before they are created.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[0;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.config' has no attribute 'list_physical_devices'"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "#print(tf.__version__)\n",
    "#print(tf.config.list_physical_devices())\n",
    "#import keras\n",
    "#print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5d1547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\GitHub\\flatiron-data-science\\phase04\\project\\Pneumonia-detection-using-CNN\\Train_Test_Folder\\\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "data_path = os.path.join(os.path.abspath(os.getcwd()),'Train_Test_Folder\\\\')\n",
    "#data_path = os.path.join(os.path.abspath(os.getcwd()),'archive\\\\chest_xray')\n",
    "print(data_path)\n",
    "\n",
    "train_dir = os.path.join(data_path, 'train\\\\')\n",
    "test_dir = os.path.join(data_path, 'test\\\\')\n",
    "#val_dir = os.path.join(data_path, 'val\\\\')\n",
    "\n",
    "train_normal = os.path.join(train_dir, 'NORMAL\\\\')\n",
    "train_pneumonia = os.path.join(train_dir, 'PNEUMONIA\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a55d6bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8312\\2835166229.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Show a representative image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "# Show a representative image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f'Image number: {len(os.listdir(train_normal))}')\n",
    "rand_norm = np.random.randint(0, len(os.listdir(train_normal)))\n",
    "norm_img = os.listdir(train_normal)[rand_norm]\n",
    "print('normal picture title: ', norm_img)\n",
    "norm_img_address = train_normal+norm_img\n",
    "\n",
    "#Pneumonia\n",
    "rand_p = np.random.randint(0,len(os.listdir(train_pneumonia)))\n",
    "\n",
    "pneu_img =  os.listdir(train_pneumonia)[rand_norm]\n",
    "pneu_img_address = train_pneumonia+pneu_img\n",
    "print('pneumonia picture title:', pneu_img)\n",
    "\n",
    "# Load the image\n",
    "norm_load = Image.open(norm_img_address)\n",
    "pneu_load = Image.open(pneu_img_address)\n",
    "\n",
    "# Show the picture\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "img_plot = plt.imshow(norm_load, cmap='gray')\n",
    "ax1.set_title('Normal')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "img_plot = plt.imshow(pneu_load, cmap='gray')\n",
    "ax2.set_title('Pneumonia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023ebee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the normal and pneumonia data evently split?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1058ff1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'image_dataset_from_directory' from 'tensorflow.keras.utils' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8312\\2019732758.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import data into tensorflow Dataset object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage_dataset_from_directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'image_dataset_from_directory' from 'tensorflow.keras.utils' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Import data into tensorflow Dataset object\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4e9213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4684 files belonging to 2 classes.\n",
      "Using 3748 files for training.\n",
      "Found 4684 files belonging to 2 classes.\n",
      "Using 936 files for validation.\n",
      "Found 1172 files belonging to 2 classes.\n",
      "Batches for testing --> tf.Tensor(37, shape=(), dtype=int64)\n",
      "Batches for validating --> tf.Tensor(30, shape=(), dtype=int64)\n",
      "Batches for training --> tf.Tensor(118, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "img_height = 64\n",
    "img_width = 64\n",
    "rgb = 3\n",
    "grayscale = 1\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = image_dataset_from_directory(train_dir,\n",
    "                                        color_mode='grayscale',\n",
    "                                        label_mode='binary',\n",
    "                                        validation_split=0.2,\n",
    "                                        subset='training',\n",
    "                                        seed=42,\n",
    "                                        #shuffle=False,\n",
    "                                        image_size=(img_height, img_width),\n",
    "                                        batch_size = batch_size)\n",
    "\n",
    "#A possible issue is that Keras validation_split uses the \"last x percent\" \n",
    "# of data as validation data without shuffling the data. \n",
    "# So if your data has a certain stratification, this stratification will \n",
    "# affect the validation set.\n",
    "val_ds = image_dataset_from_directory(train_dir,\n",
    "                                      validation_split=0.2,\n",
    "                                      color_mode='grayscale',\n",
    "                                      label_mode='binary',\n",
    "                                      subset=\"validation\",\n",
    "                                      seed=42,\n",
    "                                      #shuffle=False,\n",
    "                                      image_size=(img_height, img_width),\n",
    "                                      batch_size=batch_size)\n",
    "\n",
    "test_ds = image_dataset_from_directory(test_dir,\n",
    "                                       shuffle=False,\n",
    "                                       color_mode='grayscale',\n",
    "                                       label_mode='binary',\n",
    "                                       image_size=(img_height, img_width)\n",
    "                                      )\n",
    "\n",
    "print('Batches for testing -->', test_ds.cardinality())\n",
    "print('Batches for validating -->', val_ds.cardinality())\n",
    "print('Batches for training -->', train_ds.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e98d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal', 'pneumonia']\n",
      "(32, 64, 64, 1)\n",
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.class_names)\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61310cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the dataset for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Dataset.cache keeps the images in memory after they're loaded off disk during the first epoch. \n",
    "# This will ensure the dataset does not become a bottleneck while training your model.\n",
    "# Dataset.prefetch overlaps data preprocessing and model execution while training.\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2815916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for neural networks\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Rescaling\n",
    "from keras.metrics import SpecificityAtSensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8427a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fun(model):\n",
    "    acc = model.history['accuracy']\n",
    "    val_acc = model.history['val_accuracy']\n",
    "\n",
    "    loss = model.history['loss']\n",
    "    val_loss = model.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, 'g-', label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, 'r-', label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, 'g-', label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, 'r-', label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "#plot_fun(baseline_cnn_fit)\n",
    "# Visualize training results\n",
    "#plot_fun(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1969bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 18433     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111,105\n",
      "Trainable params: 111,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 57s 141ms/step - loss: 1.2834 - accuracy: 0.8565 - recall: 0.9084 - specificity_at_sensitivity: 0.9304 - val_loss: 0.1583 - val_accuracy: 0.9476 - val_recall: 0.9638 - val_specificity_at_sensitivity: 0.9959\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.1693 - accuracy: 0.9320 - recall: 0.9578 - specificity_at_sensitivity: 0.9951 - val_loss: 0.1971 - val_accuracy: 0.9263 - val_recall: 0.9174 - val_specificity_at_sensitivity: 1.0000\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.1244 - accuracy: 0.9530 - recall: 0.9688 - specificity_at_sensitivity: 0.9980 - val_loss: 0.1259 - val_accuracy: 0.9562 - val_recall: 0.9725 - val_specificity_at_sensitivity: 0.9959\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.1016 - accuracy: 0.9640 - recall: 0.9780 - specificity_at_sensitivity: 0.9971 - val_loss: 0.1370 - val_accuracy: 0.9573 - val_recall: 0.9754 - val_specificity_at_sensitivity: 0.9837\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.0959 - accuracy: 0.9629 - recall: 0.9743 - specificity_at_sensitivity: 0.9971 - val_loss: 0.2223 - val_accuracy: 0.9412 - val_recall: 0.9899 - val_specificity_at_sensitivity: 0.9553\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 3s 29ms/step - loss: 0.0894 - accuracy: 0.9696 - recall: 0.9817 - specificity_at_sensitivity: 0.9941 - val_loss: 0.1463 - val_accuracy: 0.9476 - val_recall: 0.9580 - val_specificity_at_sensitivity: 0.9919\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.0703 - accuracy: 0.9776 - recall: 0.9861 - specificity_at_sensitivity: 0.9990 - val_loss: 0.1481 - val_accuracy: 0.9530 - val_recall: 0.9768 - val_specificity_at_sensitivity: 0.9878\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.0581 - accuracy: 0.9792 - recall: 0.9864 - specificity_at_sensitivity: 0.9971 - val_loss: 0.1693 - val_accuracy: 0.9402 - val_recall: 0.9536 - val_specificity_at_sensitivity: 0.9959\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.0546 - accuracy: 0.9816 - recall: 0.9875 - specificity_at_sensitivity: 0.9990 - val_loss: 0.1509 - val_accuracy: 0.9551 - val_recall: 0.9696 - val_specificity_at_sensitivity: 0.9756\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.0363 - accuracy: 0.9880 - recall: 0.9927 - specificity_at_sensitivity: 0.9990 - val_loss: 0.1570 - val_accuracy: 0.9583 - val_recall: 0.9681 - val_specificity_at_sensitivity: 0.9797\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 4s 31ms/step - loss: 0.0367 - accuracy: 0.9893 - recall: 0.9941 - specificity_at_sensitivity: 0.9980 - val_loss: 0.2363 - val_accuracy: 0.9370 - val_recall: 0.9304 - val_specificity_at_sensitivity: 0.9919\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 4s 30ms/step - loss: 0.0286 - accuracy: 0.9909 - recall: 0.9952 - specificity_at_sensitivity: 0.9980 - val_loss: 0.1686 - val_accuracy: 0.9498 - val_recall: 0.9609 - val_specificity_at_sensitivity: 0.9878\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.0323 - accuracy: 0.9883 - recall: 0.9916 - specificity_at_sensitivity: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9519 - val_recall: 0.9580 - val_specificity_at_sensitivity: 0.9756\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 5s 41ms/step - loss: 0.0298 - accuracy: 0.9901 - recall: 0.9938 - specificity_at_sensitivity: 0.9990 - val_loss: 0.2097 - val_accuracy: 0.9391 - val_recall: 0.9391 - val_specificity_at_sensitivity: 0.9837\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.0398 - accuracy: 0.9848 - recall: 0.9894 - specificity_at_sensitivity: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9541 - val_recall: 0.9797 - val_specificity_at_sensitivity: 0.9634\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 4s 34ms/step - loss: 0.0280 - accuracy: 0.9891 - recall: 0.9934 - specificity_at_sensitivity: 0.9990 - val_loss: 0.2391 - val_accuracy: 0.9487 - val_recall: 0.9681 - val_specificity_at_sensitivity: 0.9593\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 4s 35ms/step - loss: 0.0256 - accuracy: 0.9909 - recall: 0.9930 - specificity_at_sensitivity: 0.9990 - val_loss: 0.2725 - val_accuracy: 0.9338 - val_recall: 0.9304 - val_specificity_at_sensitivity: 0.9797\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 5s 38ms/step - loss: 0.0092 - accuracy: 0.9979 - recall: 0.9993 - specificity_at_sensitivity: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9562 - val_recall: 0.9623 - val_specificity_at_sensitivity: 0.9715\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 5s 41ms/step - loss: 0.0053 - accuracy: 0.9984 - recall: 0.9989 - specificity_at_sensitivity: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9541 - val_recall: 0.9638 - val_specificity_at_sensitivity: 0.9715\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 4s 32ms/step - loss: 0.0071 - accuracy: 0.9984 - recall: 0.9993 - specificity_at_sensitivity: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9498 - val_recall: 0.9638 - val_specificity_at_sensitivity: 0.9593\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow.keras import layers\n",
    "\n",
    "# Baseline model\n",
    "inputs = keras.Input(shape=(img_height, img_width, grayscale))\n",
    "x = Conv2D(filters=32, kernel_size=3, activation='relu')(inputs)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "model_baseline = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the Neural network\n",
    "model_baseline.compile(optimizer = 'adam', \n",
    "                        loss = 'binary_crossentropy',\n",
    "                        metrics = ['accuracy', \n",
    "                                   keras.metrics.Recall(),\n",
    "                                   keras.metrics.SpecificityAtSensitivity(0.5)])\n",
    "\n",
    "# Summary\n",
    "model_baseline.summary()\n",
    "\n",
    "# Fit model\n",
    "epochs=20\n",
    "model_baseline_fit = model_baseline.fit(train_ds,\n",
    "                                         epochs=epochs,\n",
    "                                         validation_data = val_ds,\n",
    "                                         batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0dc39d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fun(model_baseline_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9af40087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_8 (Rescaling)     (None, 64, 64, 1)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 32769     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,089\n",
      "Trainable params: 33,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 4s 19ms/step - loss: 0.3869 - accuracy: 0.8314 - precision_8: 0.8503 - recall_8: 0.9326 - specificity_at_sensitivity_8: 0.9245 - sensitivity_at_specificity_8: 0.9641 - val_loss: 0.2346 - val_accuracy: 0.9145 - val_precision_8: 0.9024 - val_recall_8: 0.9913 - val_specificity_at_sensitivity_8: 0.9837 - val_sensitivity_at_specificity_8: 0.9971\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.2039 - accuracy: 0.9232 - precision_8: 0.9335 - recall_8: 0.9630 - specificity_at_sensitivity_8: 0.9961 - sensitivity_at_specificity_8: 0.9930 - val_loss: 0.1621 - val_accuracy: 0.9476 - val_precision_8: 0.9559 - val_recall_8: 0.9739 - val_specificity_at_sensitivity_8: 0.9959 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1674 - accuracy: 0.9370 - precision_8: 0.9498 - recall_8: 0.9644 - specificity_at_sensitivity_8: 0.9971 - sensitivity_at_specificity_8: 0.9960 - val_loss: 0.1537 - val_accuracy: 0.9434 - val_precision_8: 0.9583 - val_recall_8: 0.9652 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1409 - accuracy: 0.9480 - precision_8: 0.9594 - recall_8: 0.9696 - specificity_at_sensitivity_8: 0.9971 - sensitivity_at_specificity_8: 0.9989 - val_loss: 0.1554 - val_accuracy: 0.9487 - val_precision_8: 0.9471 - val_recall_8: 0.9855 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 1s 13ms/step - loss: 0.1446 - accuracy: 0.9448 - precision_8: 0.9552 - recall_8: 0.9696 - specificity_at_sensitivity_8: 0.9980 - sensitivity_at_specificity_8: 0.9982 - val_loss: 0.1412 - val_accuracy: 0.9487 - val_precision_8: 0.9612 - val_recall_8: 0.9696 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 1s 13ms/step - loss: 0.1302 - accuracy: 0.9506 - precision_8: 0.9625 - recall_8: 0.9699 - specificity_at_sensitivity_8: 0.9971 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9530 - val_precision_8: 0.9524 - val_recall_8: 0.9855 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1206 - accuracy: 0.9565 - precision_8: 0.9659 - recall_8: 0.9747 - specificity_at_sensitivity_8: 0.9980 - sensitivity_at_specificity_8: 0.9982 - val_loss: 0.1412 - val_accuracy: 0.9455 - val_precision_8: 0.9637 - val_recall_8: 0.9623 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.1172 - accuracy: 0.9581 - precision_8: 0.9659 - recall_8: 0.9769 - specificity_at_sensitivity_8: 0.9971 - sensitivity_at_specificity_8: 0.9996 - val_loss: 0.1368 - val_accuracy: 0.9476 - val_precision_8: 0.9652 - val_recall_8: 0.9638 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1108 - accuracy: 0.9602 - precision_8: 0.9708 - recall_8: 0.9747 - specificity_at_sensitivity_8: 0.9971 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9530 - val_precision_8: 0.9575 - val_recall_8: 0.9797 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.1045 - accuracy: 0.9613 - precision_8: 0.9691 - recall_8: 0.9780 - specificity_at_sensitivity_8: 0.9980 - sensitivity_at_specificity_8: 0.9996 - val_loss: 0.1341 - val_accuracy: 0.9509 - val_precision_8: 0.9721 - val_recall_8: 0.9609 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.0997 - accuracy: 0.9642 - precision_8: 0.9713 - recall_8: 0.9798 - specificity_at_sensitivity_8: 0.9990 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9402 - val_precision_8: 0.9760 - val_recall_8: 0.9420 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.0968 - accuracy: 0.9656 - precision_8: 0.9744 - recall_8: 0.9784 - specificity_at_sensitivity_8: 1.0000 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9530 - val_precision_8: 0.9708 - val_recall_8: 0.9652 - val_specificity_at_sensitivity_8: 0.9959 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.0916 - accuracy: 0.9672 - precision_8: 0.9745 - recall_8: 0.9806 - specificity_at_sensitivity_8: 1.0000 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9444 - val_precision_8: 0.9382 - val_recall_8: 0.9899 - val_specificity_at_sensitivity_8: 0.9837 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.0903 - accuracy: 0.9701 - precision_8: 0.9753 - recall_8: 0.9839 - specificity_at_sensitivity_8: 0.9980 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9498 - val_precision_8: 0.9749 - val_recall_8: 0.9565 - val_specificity_at_sensitivity_8: 0.9959 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 1s 13ms/step - loss: 0.0844 - accuracy: 0.9720 - precision_8: 0.9792 - recall_8: 0.9824 - specificity_at_sensitivity_8: 0.9980 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9455 - val_precision_8: 0.9762 - val_recall_8: 0.9493 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 1s 12ms/step - loss: 0.0830 - accuracy: 0.9728 - precision_8: 0.9782 - recall_8: 0.9846 - specificity_at_sensitivity_8: 0.9980 - sensitivity_at_specificity_8: 0.9996 - val_loss: 0.1310 - val_accuracy: 0.9551 - val_precision_8: 0.9642 - val_recall_8: 0.9754 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 2s 14ms/step - loss: 0.0797 - accuracy: 0.9741 - precision_8: 0.9775 - recall_8: 0.9872 - specificity_at_sensitivity_8: 0.9990 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9519 - val_precision_8: 0.9485 - val_recall_8: 0.9884 - val_specificity_at_sensitivity_8: 0.9837 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 2s 15ms/step - loss: 0.0715 - accuracy: 0.9760 - precision_8: 0.9814 - recall_8: 0.9857 - specificity_at_sensitivity_8: 1.0000 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9573 - val_precision_8: 0.9710 - val_recall_8: 0.9710 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.0795 - accuracy: 0.9728 - precision_8: 0.9785 - recall_8: 0.9842 - specificity_at_sensitivity_8: 0.9990 - sensitivity_at_specificity_8: 0.9996 - val_loss: 0.1305 - val_accuracy: 0.9562 - val_precision_8: 0.9656 - val_recall_8: 0.9754 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 2s 13ms/step - loss: 0.0681 - accuracy: 0.9771 - precision_8: 0.9825 - recall_8: 0.9861 - specificity_at_sensitivity_8: 0.9990 - sensitivity_at_specificity_8: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9455 - val_precision_8: 0.9705 - val_recall_8: 0.9551 - val_specificity_at_sensitivity_8: 1.0000 - val_sensitivity_at_specificity_8: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# CNN model\n",
    "cnn = Sequential()\n",
    "\n",
    "# Rescaling\n",
    "cnn.add(Rescaling(1./255, input_shape=(img_height, img_width, grayscale)))\n",
    "\n",
    "#Convolution\n",
    "cnn.add(Conv2D(32, (3, 3), \n",
    "               padding='same',\n",
    "               activation=\"relu\", \n",
    "               input_shape=(img_height, img_width, grayscale)))\n",
    "\n",
    "#Pooling\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# 2nd Convolution\n",
    "#cnn.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "\n",
    "# 2nd Pooling layer\n",
    "#cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flatten the layer\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Fully Connected Layers\n",
    "#cnn.add(Dense(activation = 'relu', units = 128))\n",
    "cnn.add(Dense(activation = 'sigmoid', units = 1))\n",
    "\n",
    "# Compile the Neural network\n",
    "cnn.compile(optimizer = 'adam', \n",
    "            loss = 'binary_crossentropy',\n",
    "            metrics = ['accuracy', \n",
    "                       keras.metrics.Precision(),\n",
    "                       keras.metrics.Recall(),\n",
    "                       keras.metrics.SpecificityAtSensitivity(0.5),\n",
    "                       keras.metrics.SensitivityAtSpecificity(0.5)])\n",
    "\n",
    "# Summary\n",
    "cnn.summary()\n",
    "\n",
    "# Fit model\n",
    "epochs=20\n",
    "cnn_model = cnn.fit(train_ds,\n",
    "                    #steps_per_epoch = 163,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8455dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b6e9d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_3 (Rescaling)     (None, 64, 64, 1)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               4194432   \n",
      "                                                                 \n",
      " sigmoid (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,194,881\n",
      "Trainable params: 4,194,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'assert_greater_equal/Assert/AssertGuard/Assert' defined at (most recent call last):\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_13064\\3856174219.py\", line 38, in <cell line: 38>\n      baseline_cnn_fit = baseline_cnn.fit(train_ds,\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 894, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 987, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 501, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 818, in update_state\n      return metrics_utils.update_confusion_matrix_variables(\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 602, in update_confusion_matrix_variables\n      tf.debugging.assert_greater_equal(\nNode: 'assert_greater_equal/Assert/AssertGuard/Assert'\nassertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (sequential_3/sigmoid/BiasAdd:0) = ] [[-0.155957013][-0.128160834][-0.132769421]...] [y (Cast_6/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_33911]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[0;32m     37\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m---> 38\u001b[0m baseline_cnn_fit \u001b[38;5;241m=\u001b[39m \u001b[43mbaseline_cnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;66;43;03m#steps_per_epoch = 163,\u001b[39;49;00m\n\u001b[0;32m     40\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;66;43;03m#validation_steps= testing_set.samples\u001b[39;49;00m\n\u001b[0;32m     43\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'assert_greater_equal/Assert/AssertGuard/Assert' defined at (most recent call last):\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_13064\\3856174219.py\", line 38, in <cell line: 38>\n      baseline_cnn_fit = baseline_cnn.fit(train_ds,\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 894, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 987, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 501, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\metrics\\metrics.py\", line 818, in update_state\n      return metrics_utils.update_confusion_matrix_variables(\n    File \"D:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 602, in update_confusion_matrix_variables\n      tf.debugging.assert_greater_equal(\nNode: 'assert_greater_equal/Assert/AssertGuard/Assert'\nassertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (sequential_3/sigmoid/BiasAdd:0) = ] [[-0.155957013][-0.128160834][-0.132769421]...] [y (Cast_6/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_33911]"
     ]
    }
   ],
   "source": [
    "# baseline model\n",
    "baseline_cnn = Sequential()\n",
    "\n",
    "# Rescaling\n",
    "baseline_cnn.add(Rescaling(1./255, input_shape=(img_height, img_width, grayscale)))\n",
    "\n",
    "#Convolution\n",
    "baseline_cnn.add(Conv2D(32, (3, 3),\n",
    "                        padding='same',\n",
    "                        activation=\"relu\", \n",
    "                        input_shape=(img_height, img_width, grayscale)))\n",
    "\n",
    "#Pooling\n",
    "baseline_cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flatten\n",
    "baseline_cnn.add(Flatten())\n",
    "\n",
    "baseline_cnn.add(Dense(activation = 'relu', units = 128))\n",
    "\n",
    "# Output Layer\n",
    "baseline_cnn.add(Dense(units=1, name='sigmoid'))\n",
    "\n",
    "# Compile the Neural network\n",
    "baseline_cnn.compile(optimizer = 'adam', \n",
    "                     loss = 'binary_crossentropy',\n",
    "                     metrics = ['accuracy', \n",
    "                                keras.metrics.Precision(),\n",
    "                                keras.metrics.Recall(),\n",
    "                                keras.metrics.SpecificityAtSensitivity(0.5),\n",
    "                                keras.metrics.SensitivityAtSpecificity(0.5)])\n",
    "\n",
    "# Summary\n",
    "baseline_cnn.summary()\n",
    "\n",
    "# Fit\n",
    "epochs = 20\n",
    "baseline_cnn_fit = baseline_cnn.fit(train_ds,\n",
    "                                   #steps_per_epoch = 163,\n",
    "                                   epochs=epochs,\n",
    "                                   validation_data = val_ds,\n",
    "                                   #validation_steps= testing_set.samples\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5615caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "from keras.layers import RandomFlip\n",
    "from keras.layers import RandomRotation\n",
    "from keras.layers import RandomZoom\n",
    "\n",
    "rescale = Sequential([Rescaling(1./255)])\n",
    "\n",
    "data_augmentation = keras.Sequential([\n",
    "                                RandomFlip(\"horizontal\",\n",
    "                                        input_shape=(img_height, img_width, 1)),\n",
    "                                RandomRotation(0.1),\n",
    "                                RandomZoom(0.1)\n",
    "                    ])\n",
    "\n",
    "# Visualize a few augmented examples by applying data augmentation to the same image several times:\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"),cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc57cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug = Sequential([rescale,\n",
    "                        data_augmentation,\n",
    "                        Conv2D(32, (3,3), \n",
    "                               padding='same', \n",
    "                               activation='relu', \n",
    "                               input_shape=(img_height, img_width, 1)),\n",
    "                        MaxPooling2D(pool_size=(2,2)),\n",
    "                        Conv2D(32, (3,3), \n",
    "                               padding='same', \n",
    "                               activation='relu'),\n",
    "                        MaxPooling2D(pool_size=(2,2)),\n",
    "                        Flatten(),\n",
    "                        Dense(128, activation='relu'),\n",
    "                        Dense(units=1, name=\"sigmoid\")\n",
    "                        ])\n",
    "# Compile the Neural network\n",
    "model_aug.compile(optimizer = 'adam', \n",
    "                   loss = 'binary_crossentropy',\n",
    "                   metrics = ['accuracy', \n",
    "                              keras.metrics.Precision(),\n",
    "                              keras.metrics.Recall(),\n",
    "                              keras.metrics.SpecificityAtSensitivity(0.5),\n",
    "                              keras.metrics.SensitivityAtSpecificity(0.5)])\n",
    "\n",
    "# Summary\n",
    "#model_aug.summary()\n",
    "\n",
    "# Fit model\n",
    "#epochs=20\n",
    "#cnn_aug_model = model_augmentation.fit(train_ds,\n",
    "                                       #steps_per_epoch = 163,\n",
    "#                                       epochs=epochs,\n",
    "#                                       validation_data = val_ds,\n",
    "                                       #validation_steps= testing_set.samples\n",
    "#                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12dd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with transfer learning\n",
    "from keras.applications import VGG19\n",
    "\n",
    "cnn_vgg19 = VGG19(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(img_height, img_width, rgb))\n",
    "\n",
    "cnn_vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer = Sequential([\n",
    "                          data_augmentation,\n",
    "                          Rescaling(1./255, input_shape=(img_height, img_width,1)),\n",
    "                          Conv2D(32, (3,3), \n",
    "                                 padding='same', \n",
    "                                 activation='relu', \n",
    "                                 input_shape=(img_height, img_width, 1)),\n",
    "                          MaxPooling2D(pool_size=(2,2)),\n",
    "                          Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "                          MaxPooling2D(pool_size=(2,2)),\n",
    "                          Dropout(0.2),\n",
    "                          Flatten(),\n",
    "                          Dense(128, activation='relu'),\n",
    "                          Dense(units=1, name=\"sigmoid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
